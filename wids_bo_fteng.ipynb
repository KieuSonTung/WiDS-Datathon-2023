{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder, LabelEncoder, RobustScaler, StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error\n",
    "from sklearn.linear_model import Ridge, Lasso, LassoCV, LinearRegression\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy.ma as ma\n",
    "from sklearn import base\n",
    "import warnings\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "path_train = \"data/train_data.csv\"\n",
    "path_test = \"data/test_data.csv\"\n",
    "target_ = \"contest-tmp2m-14d__tmp2m\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(path_train)\n",
    "df_test = pd.read_csv(path_test)\n",
    "\n",
    "date_col = \"startdate\"\n",
    "target_ = 'contest-tmp2m-14d__tmp2m'\n",
    "\n",
    "df_train[date_col] = pd.to_datetime(df_train[date_col])\n",
    "df_test[date_col] = pd.to_datetime(df_test[date_col])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "   index  lat       lon  startdate  contest-pevpr-sfc-gauss-14d__pevpr  \\\n0      0  0.0  0.833333 2014-09-01                              237.00   \n1      1  0.0  0.833333 2014-09-02                              228.90   \n2      2  0.0  0.833333 2014-09-03                              220.69   \n3      3  0.0  0.833333 2014-09-04                              225.28   \n4      4  0.0  0.833333 2014-09-05                              237.24   \n\n   nmme0-tmp2m-34w__cancm30  nmme0-tmp2m-34w__cancm40  \\\n0                     29.02                     31.64   \n1                     29.02                     31.64   \n2                     29.02                     31.64   \n3                     29.02                     31.64   \n4                     29.02                     31.64   \n\n   nmme0-tmp2m-34w__ccsm30  nmme0-tmp2m-34w__ccsm40  nmme0-tmp2m-34w__cfsv20  \\\n0                    29.57                    30.73                    29.71   \n1                    29.57                    30.73                    29.71   \n2                    29.57                    30.73                    29.71   \n3                    29.57                    30.73                    29.71   \n4                    29.57                    30.73                    29.71   \n\n   ...  wind-vwnd-925-2010-11  wind-vwnd-925-2010-12  wind-vwnd-925-2010-13  \\\n0  ...                 -27.68                 -37.21                   8.32   \n1  ...                 -21.13                 -36.57                   8.77   \n2  ...                 -10.72                 -34.16                   6.99   \n3  ...                   0.33                 -31.04                   6.17   \n4  ...                   9.83                 -31.80                   7.47   \n\n   wind-vwnd-925-2010-14  wind-vwnd-925-2010-15  wind-vwnd-925-2010-16  \\\n0                   9.56                  -2.03                  48.13   \n1                  21.17                   4.44                  48.60   \n2                  32.16                   5.01                  48.53   \n3                  39.66                  -1.41                  50.59   \n4                  38.62                  -5.21                  54.73   \n\n   wind-vwnd-925-2010-17  wind-vwnd-925-2010-18  wind-vwnd-925-2010-19  \\\n0                  28.09                 -13.50                  11.90   \n1                  27.41                 -23.77                  15.44   \n2                  19.21                 -33.16                  15.11   \n3                   8.29                 -37.22                  18.24   \n4                  -2.58                 -42.30                  21.91   \n\n   wind-vwnd-925-2010-20  \n0                   4.58  \n1                   3.42  \n2                   4.82  \n3                   9.74  \n4                  10.95  \n\n[5 rows x 246 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>lat</th>\n      <th>lon</th>\n      <th>startdate</th>\n      <th>contest-pevpr-sfc-gauss-14d__pevpr</th>\n      <th>nmme0-tmp2m-34w__cancm30</th>\n      <th>nmme0-tmp2m-34w__cancm40</th>\n      <th>nmme0-tmp2m-34w__ccsm30</th>\n      <th>nmme0-tmp2m-34w__ccsm40</th>\n      <th>nmme0-tmp2m-34w__cfsv20</th>\n      <th>...</th>\n      <th>wind-vwnd-925-2010-11</th>\n      <th>wind-vwnd-925-2010-12</th>\n      <th>wind-vwnd-925-2010-13</th>\n      <th>wind-vwnd-925-2010-14</th>\n      <th>wind-vwnd-925-2010-15</th>\n      <th>wind-vwnd-925-2010-16</th>\n      <th>wind-vwnd-925-2010-17</th>\n      <th>wind-vwnd-925-2010-18</th>\n      <th>wind-vwnd-925-2010-19</th>\n      <th>wind-vwnd-925-2010-20</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.833333</td>\n      <td>2014-09-01</td>\n      <td>237.00</td>\n      <td>29.02</td>\n      <td>31.64</td>\n      <td>29.57</td>\n      <td>30.73</td>\n      <td>29.71</td>\n      <td>...</td>\n      <td>-27.68</td>\n      <td>-37.21</td>\n      <td>8.32</td>\n      <td>9.56</td>\n      <td>-2.03</td>\n      <td>48.13</td>\n      <td>28.09</td>\n      <td>-13.50</td>\n      <td>11.90</td>\n      <td>4.58</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.833333</td>\n      <td>2014-09-02</td>\n      <td>228.90</td>\n      <td>29.02</td>\n      <td>31.64</td>\n      <td>29.57</td>\n      <td>30.73</td>\n      <td>29.71</td>\n      <td>...</td>\n      <td>-21.13</td>\n      <td>-36.57</td>\n      <td>8.77</td>\n      <td>21.17</td>\n      <td>4.44</td>\n      <td>48.60</td>\n      <td>27.41</td>\n      <td>-23.77</td>\n      <td>15.44</td>\n      <td>3.42</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.833333</td>\n      <td>2014-09-03</td>\n      <td>220.69</td>\n      <td>29.02</td>\n      <td>31.64</td>\n      <td>29.57</td>\n      <td>30.73</td>\n      <td>29.71</td>\n      <td>...</td>\n      <td>-10.72</td>\n      <td>-34.16</td>\n      <td>6.99</td>\n      <td>32.16</td>\n      <td>5.01</td>\n      <td>48.53</td>\n      <td>19.21</td>\n      <td>-33.16</td>\n      <td>15.11</td>\n      <td>4.82</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.833333</td>\n      <td>2014-09-04</td>\n      <td>225.28</td>\n      <td>29.02</td>\n      <td>31.64</td>\n      <td>29.57</td>\n      <td>30.73</td>\n      <td>29.71</td>\n      <td>...</td>\n      <td>0.33</td>\n      <td>-31.04</td>\n      <td>6.17</td>\n      <td>39.66</td>\n      <td>-1.41</td>\n      <td>50.59</td>\n      <td>8.29</td>\n      <td>-37.22</td>\n      <td>18.24</td>\n      <td>9.74</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.0</td>\n      <td>0.833333</td>\n      <td>2014-09-05</td>\n      <td>237.24</td>\n      <td>29.02</td>\n      <td>31.64</td>\n      <td>29.57</td>\n      <td>30.73</td>\n      <td>29.71</td>\n      <td>...</td>\n      <td>9.83</td>\n      <td>-31.80</td>\n      <td>7.47</td>\n      <td>38.62</td>\n      <td>-5.21</td>\n      <td>54.73</td>\n      <td>-2.58</td>\n      <td>-42.30</td>\n      <td>21.91</td>\n      <td>10.95</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 246 columns</p>\n</div>"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fill null"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:03,  1.87it/s]\n"
     ]
    }
   ],
   "source": [
    "def filter_na_cols(df):\n",
    "    count_na_df = df.isna().sum()\n",
    "    if count_na_df[count_na_df > 0].tolist():\n",
    "        return count_na_df[count_na_df > 0]\n",
    "    else:\n",
    "        return 'Clean dataset'\n",
    "\n",
    "col_na = [\n",
    "    'nmme0-tmp2m-34w__ccsm30',\n",
    "    'nmme-tmp2m-56w__ccsm3',\n",
    "    'nmme-prate-34w__ccsm3',\n",
    "    'nmme0-prate-56w__ccsm30',\n",
    "    'nmme0-prate-34w__ccsm30',\n",
    "    'nmme-prate-56w__ccsm3',\n",
    "    'nmme-tmp2m-34w__ccsm3']\n",
    "\n",
    "g_means =  ['nmme0-tmp2m-34w__nmme0mean',\n",
    " 'nmme-tmp2m-56w__nmmemean',\n",
    " 'nmme-prate-34w__nmmemean',\n",
    " 'nmme0-prate-56w__nmme0mean',\n",
    " 'nmme0-prate-34w__nmme0mean',\n",
    " 'nmme-prate-56w__nmmemean',\n",
    " 'nmme-tmp2m-34w__nmmemean']\n",
    "\n",
    "\n",
    "g_1 = ['nmme0-tmp2m-34w__cancm30',\n",
    "'nmme0-tmp2m-34w__cancm40',\n",
    "'nmme0-tmp2m-34w__ccsm40',\n",
    "'nmme0-tmp2m-34w__cfsv20',\n",
    "'nmme0-tmp2m-34w__gfdlflora0',\n",
    "'nmme0-tmp2m-34w__gfdlflorb0',\n",
    "'nmme0-tmp2m-34w__gfdl0',\n",
    "'nmme0-tmp2m-34w__nasa0']\n",
    "\n",
    "g_2 = ['nmme-tmp2m-56w__cancm3',\n",
    "'nmme-tmp2m-56w__cancm4',\n",
    "'nmme-tmp2m-56w__ccsm4',\n",
    "'nmme-tmp2m-56w__cfsv2',\n",
    "'nmme-tmp2m-56w__gfdl',\n",
    "'nmme-tmp2m-56w__gfdlflora',\n",
    "'nmme-tmp2m-56w__gfdlflorb',\n",
    "'nmme-tmp2m-56w__nasa']\n",
    "\n",
    "g_3 = ['nmme-prate-34w__cancm3',\n",
    "'nmme-prate-34w__cancm4',\n",
    "'nmme-prate-34w__ccsm4',\n",
    "'nmme-prate-34w__cfsv2',\n",
    "'nmme-prate-34w__gfdl',\n",
    "'nmme-prate-34w__gfdlflora',\n",
    "'nmme-prate-34w__gfdlflorb',\n",
    "'nmme-prate-34w__nasa']\n",
    "\n",
    "g_4 = [ 'nmme0-prate-56w__cancm30',\n",
    "'nmme0-prate-56w__cancm40',\n",
    "'nmme0-prate-56w__ccsm40',\n",
    "'nmme0-prate-56w__cfsv20',\n",
    "'nmme0-prate-56w__gfdlflora0',\n",
    "'nmme0-prate-56w__gfdlflorb0',\n",
    "'nmme0-prate-56w__gfdl0',\n",
    "'nmme0-prate-56w__nasa0']\n",
    "\n",
    "g_5 = ['nmme0-prate-34w__cancm30',\n",
    "'nmme0-prate-34w__cancm40',\n",
    "'nmme0-prate-34w__ccsm40',\n",
    "'nmme0-prate-34w__cfsv20',\n",
    "'nmme0-prate-34w__gfdlflora0',\n",
    "'nmme0-prate-34w__gfdlflorb0',\n",
    "'nmme0-prate-34w__gfdl0',\n",
    "'nmme0-prate-34w__nasa0']\n",
    "\n",
    "g_6 = ['nmme-prate-56w__cancm3',\n",
    "'nmme-prate-56w__cancm4',\n",
    "'nmme-prate-56w__ccsm4',\n",
    "'nmme-prate-56w__cfsv2',\n",
    "'nmme-prate-56w__gfdl',\n",
    "'nmme-prate-56w__gfdlflora',\n",
    "'nmme-prate-56w__gfdlflorb',\n",
    "'nmme-prate-56w__nasa']\n",
    "\n",
    "g_7 = ['nmme-tmp2m-34w__cancm3',\n",
    "'nmme-tmp2m-34w__cancm4',\n",
    "'nmme-tmp2m-34w__ccsm4',\n",
    "'nmme-tmp2m-34w__cfsv2',\n",
    "'nmme-tmp2m-34w__gfdl',\n",
    "'nmme-tmp2m-34w__gfdlflora',\n",
    "'nmme-tmp2m-34w__gfdlflorb',\n",
    "'nmme-tmp2m-34w__nasa']\n",
    "\n",
    "gs = [g_1, g_2, g_3, g_4, g_5, g_6, g_7]\n",
    "\n",
    "zip_cols = zip(col_na, gs, g_means)\n",
    "for c, g, m in tqdm(zip_cols):\n",
    "    df_train[c] = (df_train[m]*9) - df_train[g].sum(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "df_train.drop(columns='ccsm30', inplace=True)\n",
    "df_test.drop(columns='ccsm30', inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature engineering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "drop_col = pd.read_csv(\"data/correlations_with_target_greater_0.7.csv\")\n",
    "drop_col = drop_col[\"col\"].values\n",
    "drop_col = [each for each in drop_col if \"contest\" not in each and \"wind\" not in each]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bining"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "bin_col = ['nmme-tmp2m-34w__cfsv2', 'nmme-tmp2m-56w__gfdlflora', 'nmme-tmp2m-56w__nasa', 'nmme0-tmp2m-34w__cancm30', 'nmme-tmp2m-56w__gfdl', 'nmme0mean']\n",
    "\n",
    "list_new_col = []\n",
    "\n",
    "def bin_feature_tpm2m(x):\n",
    "    if x < -5:\n",
    "        return 'A'\n",
    "    elif x < 0:\n",
    "        return 'B'\n",
    "    elif x < 5:\n",
    "        return 'C'\n",
    "    elif x < 10:\n",
    "        return 'D'\n",
    "    elif x < 15:\n",
    "        return 'E'\n",
    "    elif x < 20:\n",
    "        return 'F'\n",
    "    elif x < 25:\n",
    "        return 'G'\n",
    "    else:\n",
    "        return 'H'\n",
    "\n",
    "for each in bin_col:\n",
    "    df_train[each + \"_bin\"] = np.vectorize(bin_feature_tpm2m)(df_train[each])\n",
    "    df_test[each + \"_bin\"] = np.vectorize(bin_feature_tpm2m)(df_test[each])\n",
    "    list_new_col.append(each + \"_bin\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "def get_idx(lat, lon):\n",
    "    return str(round(lat, 4)) + \"_\" + str(round(lon, 4))\n",
    "\n",
    "df_train['idx'] = np.vectorize(get_idx)(df_train['lat'], df_train['lon'])\n",
    "df_test['idx'] = np.vectorize(get_idx)(df_test['lat'], df_test['lon'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "col = [each for each in df_train.columns if \"contest\" in each and each != target_]\n",
    "\n",
    "for each in col:\n",
    "    df_train[each + \"_lag_1\"] = df_train.groupby(\"idx\")[each].shift(1).bfill()\n",
    "    df_test[each + \"_lag_1\"] = df_test.groupby(\"idx\")[each].shift(1).bfill()\n",
    "    df_train[each + \"_lag_2\"] = df_train.groupby(\"idx\")[each].shift(2).bfill()\n",
    "    df_test[each + \"_lag_2\"] = df_test.groupby(\"idx\")[each].shift(2).bfill()\n",
    "    list_new_col.append(each + \"_lag_1\")\n",
    "    list_new_col.append(each + \"_lag_2\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "col_test = [each for each in df_train.columns if \"contest\" not in each and (\"wind\" in each or \"sst\" in each)]\n",
    "col_drift = [\n",
    "    \"wind-vwnd-250-2010-2\",\n",
    "    \"wind-vwnd-250-2010-16\",\n",
    "    \"wind-vwnd-250-2010-19\",\n",
    "    \"wind-uwnd-250-2010-9\",\n",
    "    \"wind-uwnd-250-2010-11\",\n",
    "    \"wind-uwnd-250-2010-17\",\n",
    "    \"wind-hgt-850-2010-2\",\n",
    "    \"wind-hgt-850-2010-5\",\n",
    "    \"wind-hgt-850-2010-7\",\n",
    "    \"sst-2010-2\",\n",
    "    \"sst-2010-10\",\n",
    "    \"wind-hgt-500-2010-5\",\n",
    "    \"wind-hgt-500-2010-7\",\n",
    "    \"wind-hgt-500-2010-8\",\n",
    "    \"wind-uwnd-925-2010-2\",\n",
    "    \"wind-uwnd-925-2010-7\",\n",
    "    \"wind-uwnd-925-2010-20\"\n",
    "]\n",
    "\n",
    "dict_col_drift = {each:True for each in col_drift}\n",
    "\n",
    "for each in col_test:\n",
    "    if each in dict_col_drift:\n",
    "        continue\n",
    "    df_train[each + \"_lag_1\"] = df_train.groupby(\"idx\")[each].shift(1).bfill()\n",
    "    df_test[each + \"_lag_1\"] = df_test.groupby(\"idx\")[each].shift(1).bfill()\n",
    "    df_train[each + \"_diff\"] = df_train.groupby(\"idx\")[each].diff().bfill()\n",
    "    df_test[each + \"_diff\"] = df_test.groupby(\"idx\")[each].diff().bfill()\n",
    "    list_new_col.append(each + \"_diff\")\n",
    "    list_new_col.append(each + \"_lag_1\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "def create_mean_group(df, cols_group, cols_mean, col_date=\"startdate\"):\n",
    "    list_new_col = []\n",
    "    df[col_date] = df[col_date].astype(\"str\")\n",
    "\n",
    "    for col_mean in cols_mean:\n",
    "        for col_group in cols_group:\n",
    "            new_col = col_mean + \"_{}\".format(col_group) + \"_mean\"\n",
    "            dict_map = df.groupby([col_group, col_date])[col_mean].mean().to_dict()\n",
    "\n",
    "            def map_dict(gr, date):\n",
    "                return dict_map[gr, date]\n",
    "\n",
    "            df[new_col] = np.vectorize(map_dict)(df[col_group], df[col_date])\n",
    "            list_new_col.append(new_col)\n",
    "\n",
    "    df[col_date] = pd.to_datetime(df[col_date])\n",
    "\n",
    "    return df, list_new_col\n",
    "\n",
    "cols_group = [\"lat\", \"lon\", \"climateregions__climateregion\"]\n",
    "df_train, list_col = create_mean_group(df_train, cols_group, col)\n",
    "df_test, _ = create_mean_group(df_test, cols_group, col)\n",
    "list_new_col = [*list_new_col, *list_col]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "def get_name_cols(suffix='', cols=[]):\n",
    "    name_cols = [col + f'{suffix}' for col in cols if col != 'contest-tmp2m-14d__tmp2m']\n",
    "\n",
    "    return name_cols\n",
    "\n",
    "# Add wind features\n",
    "\n",
    "def feature_engineer(df, cols):\n",
    "    rolling_mean_contest_cols_3 = df.groupby('idx')[cols].transform(lambda x: x.rolling(window=3, min_periods=2).mean()) \\\n",
    "        .rename(columns=dict(zip(cols, get_name_cols('_rolling_mean_3', cols))))\n",
    "    rolling_std_contest_cols_3 = df.groupby('idx')[cols].transform(lambda x: x.rolling(window=3, min_periods=2).std()) \\\n",
    "        .rename(columns=dict(zip(cols, get_name_cols('_rolling_std_3', cols))))\n",
    "    rolling_mean_contest_cols_6 = df.groupby('idx')[cols].transform(lambda x: x.rolling(window=6, min_periods=2).mean()) \\\n",
    "        .rename(columns=dict(zip(cols, get_name_cols('_rolling_mean_6', cols))))\n",
    "    rolling_std_contest_cols_6 = df.groupby('idx')[cols].transform(lambda x: x.rolling(window=6, min_periods=2).std()) \\\n",
    "        .rename(columns=dict(zip(cols, get_name_cols('_rolling_std_6', cols))))\n",
    "    diff_contest_cols = df.groupby('idx')[cols].transform(lambda x: x.diff()) \\\n",
    "        .rename(columns=dict(zip(cols, get_name_cols('_diff', cols))))\n",
    "    exponentially_weighted_average = df.groupby('idx')[cols].transform(lambda x: x.shift(1).ewm(alpha=0.95).mean()) \\\n",
    "        .rename(columns=dict(zip(cols, get_name_cols('_ewa', cols))))\n",
    "\n",
    "    df = pd.concat([df, rolling_mean_contest_cols_3, rolling_std_contest_cols_3,\n",
    "                    rolling_mean_contest_cols_6, rolling_std_contest_cols_6, diff_contest_cols,\n",
    "                    exponentially_weighted_average], axis=1)\n",
    "    df = df.fillna(method='bfill')\n",
    "\n",
    "    return df\n",
    "\n",
    "def feature_engineer_2(df, cols):\n",
    "    rolling_mean_contest_cols_3 = df.groupby('idx')[cols].transform(lambda x: x.rolling(window=3, min_periods=2).mean()) \\\n",
    "        .rename(columns=dict(zip(cols, get_name_cols('_rolling_mean_3', cols))))\n",
    "    rolling_std_contest_cols_3 = df.groupby('idx')[cols].transform(lambda x: x.rolling(window=3, min_periods=2).std()) \\\n",
    "        .rename(columns=dict(zip(cols, get_name_cols('_rolling_std_3', cols))))\n",
    "    # diff_contest_cols = df.groupby('idx')[cols].transform(lambda x: x.diff()) \\\n",
    "    #     .rename(columns=dict(zip(cols, get_name_cols('_diff', cols))))\n",
    "    exponentially_weighted_average = df.groupby('idx')[cols].transform(lambda x: x.shift(1).ewm(alpha=0.95).mean()) \\\n",
    "        .rename(columns=dict(zip(cols, get_name_cols('_ewa', cols))))\n",
    "\n",
    "    df = pd.concat([df, rolling_mean_contest_cols_3,\n",
    "                    rolling_std_contest_cols_3,\n",
    "                    exponentially_weighted_average],\n",
    "                   axis=1)\n",
    "    df = df.fillna(method='bfill')\n",
    "\n",
    "    return df\n",
    "\n",
    "imp_contest_cols = [\n",
    "    'contest-pevpr-sfc-gauss-14d__pevpr',\n",
    "    'contest-pres-sfc-gauss-14d__pres',\n",
    "    'contest-prwtr-eatm-14d__prwtr',\n",
    "    'contest-slp-14d__slp',\n",
    "    'contest-wind-h10-14d__wind-hgt-10',\n",
    "    'contest-wind-h100-14d__wind-hgt-100',\n",
    "    'contest-wind-h500-14d__wind-hgt-500',\n",
    "    'contest-wind-uwnd-250-14d__wind-uwnd-250',\n",
    "    'contest-wind-vwnd-925-14d__wind-vwnd-925'\n",
    "]\n",
    "\n",
    "drift_nnme_prate_cols = [\n",
    "    * [col for col in col_test if col not in dict_col_drift],\n",
    "    * [col for col in df_train.columns if 'nmme-prate' in col or 'nmme0-prate' in col]\n",
    "]\n",
    "\n",
    "df_train = feature_engineer(df_train, imp_contest_cols)\n",
    "df_test = feature_engineer(df_test, imp_contest_cols)\n",
    "\n",
    "df_train = feature_engineer_2(df_train, drift_nnme_prate_cols)\n",
    "df_test = feature_engineer_2(df_test, drift_nnme_prate_cols)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "col_ = [each for each in df_train.columns if \"_rolling\" in each or \"_ewa\" in each]\n",
    "list_new_col = [*list_new_col, *col_]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "def sin_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.sin(x / period * 2 * np.pi))\n",
    "\n",
    "def cos_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.cos(x / period * 2 * np.pi))\n",
    "\n",
    "def handle_idx_date(df, column_date, idx_name):\n",
    "    def get_idx(lat, lon):\n",
    "        return str(round(lat, 4)) + \"_\" + str(round(lon, 4))\n",
    "    df[idx_name] = np.vectorize(get_idx)(df['lat'], df['lon'])\n",
    "    if column_date is not None:\n",
    "        df[column_date] = pd.to_datetime(df[column_date])\n",
    "        df['day_of_year'] = df[column_date].dt.day_of_year\n",
    "        df['month'] = df[column_date].dt.month\n",
    "          # encode the day with a period of 365\n",
    "        df['day_of_year_sin'] = sin_transformer(365).fit_transform(df['day_of_year'])\n",
    "        df['day_of_year_cos'] = cos_transformer(365).fit_transform(df['day_of_year'])\n",
    "\n",
    "        # encode the month with a period of 12\n",
    "        df['month_sin'] = sin_transformer(12).fit_transform(df['month'])\n",
    "        df['month_cos'] = cos_transformer(12).fit_transform(df['month'])\n",
    "    return df\n",
    "\n",
    "def handle_feature_train_data(df, column_date=\"startdate\", columns_cat = [], idx_name=\"idx\", norm=\"min_max\"):\n",
    "    df = handle_idx_date(df, column_date, idx_name)\n",
    "    if column_date is not None:\n",
    "        df = df.drop(columns = [column_date])\n",
    "    columns_cat.append(idx_name)\n",
    "    list_lbEncoder = []\n",
    "\n",
    "    for each in columns_cat:\n",
    "        lbE = LabelEncoder().fit(df[each])\n",
    "        df[each] = lbE.transform(df[each])\n",
    "        list_lbEncoder.append(lbE)\n",
    "\n",
    "    # for each in df.columns:\n",
    "    #     if df[each].isna().sum() != 0:\n",
    "    #         df[each] = df.groupby(idx_name)[each].transform(lambda x: x.ffill())\n",
    "\n",
    "    df[columns_cat] = df[columns_cat].astype(\"category\")\n",
    "\n",
    "    X = None\n",
    "    if norm == \"min_max\":\n",
    "        X = MinMaxScaler().fit_transform(df.values)\n",
    "    elif norm == \"std\":\n",
    "        X = StandardScaler().fit_transform(df.values)\n",
    "\n",
    "    return df, X, list_lbEncoder\n",
    "\n",
    "def handle_feature_test_data(df, lbEncoder, column_date=\"startdate\", columns_cat = [], idx_name=\"idx\"):\n",
    "    df = handle_idx_date(df, column_date, idx_name)\n",
    "    if column_date is not None:\n",
    "        df = df.drop(columns = [column_date])\n",
    "    columns_cat.append(idx_name)\n",
    "\n",
    "    for index, each in enumerate(columns_cat):\n",
    "        df[each] = lbEncoder[index].transform(df[each])\n",
    "\n",
    "    # for each in df.columns:\n",
    "    #     if df[each].isna().sum() != 0:\n",
    "    #         df[each] = df.groupby(idx_name)[each].transform(lambda x: x.ffill())\n",
    "\n",
    "    df[columns_cat] = df[columns_cat].astype(\"category\")\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "def reconvert(df):\n",
    "    if not os.path.exists('delete_later'):\n",
    "        os.mkdir('delete_later')\n",
    "\n",
    "    df.to_csv('delete_later/df.csv')\n",
    "    df = pd.read_csv('delete_later/df.csv')\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "def calculate_corr_target(X_train, X_val):\n",
    "    data_col = []\n",
    "    data_corr_train = []\n",
    "    data_corr_val = []\n",
    "\n",
    "    for col in X_train.columns:\n",
    "        corr_train = X_train['contest-tmp2m-14d__tmp2m'].corr(X_train[col])\n",
    "        corr_val = X_val['contest-tmp2m-14d__tmp2m'].corr(X_val[col])\n",
    "\n",
    "        data_col.append(col)\n",
    "        data_corr_train.append(corr_train)\n",
    "        data_corr_val.append(corr_val)\n",
    "\n",
    "    corr = pd.DataFrame(data={'col': data_col, 'corr_train': data_corr_train, 'corr_val': data_corr_val})\n",
    "\n",
    "    return corr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "corr_df = pd.read_csv(\"data/correlations_with_target.csv\") \\\n",
    "            .drop(columns='Unnamed: 0')\n",
    "corr_df = corr_df[(corr_df['corr'] >= 0.7)  | (corr_df['corr'] <= -0.7)]\n",
    "drop_col = corr_df[\"col\"].values\n",
    "drop_col = [each for each in drop_col if \"contest\" not in each and \"wind\" not in each and each != 'ccsm30']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LGBM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "def bayes_tunning():\n",
    "    def CB_opt(max_depth, num_leaves, colsample_bytree, reg_alpha,\n",
    "               reg_lambda, subsample, feature_fraction_bynode):\n",
    "\n",
    "        lgb = LGBMRegressor(\n",
    "            max_depth = round(max_depth),\n",
    "            num_leaves=round(num_leaves),\n",
    "            colsample_bytree=colsample_bytree,\n",
    "            reg_alpha=reg_alpha,\n",
    "            reg_lambda=reg_lambda,\n",
    "            subsample=subsample,\n",
    "            feature_fraction_bynode=feature_fraction_bynode,\n",
    "            verbose=0,\n",
    "            n_estimators = 7999,\n",
    "            metric=\"rmse\",\n",
    "            boosting_type=\"dart\",\n",
    "            learning_rate=0.05,\n",
    "            n_jobs=-1,\n",
    "            extra_trees=True\n",
    "        )\n",
    "\n",
    "        lgb.fit(X_train, y_train, eval_metric=\"rmse\",\n",
    "                categorical_feature=[\n",
    "                    'climateregions__climateregion', 'idx', 'mjo1d__phase',\n",
    "                    'nmme-tmp2m-34w__nmmemean_bin', 'nmme-tmp2m-56w__nmmemean_bin',\n",
    "                    'nmme0-tmp2m-34w__nmme0mean_bin', 'nmme0mean_bin'\n",
    "                ]\n",
    "                )\n",
    "        ypred_valid = lgb.predict(X_valid)\n",
    "\n",
    "        return 1 / mean_squared_error(y_valid, ypred_valid, squared=False)\n",
    "\n",
    "    pbounds = {\n",
    "        'max_depth': (8, 17),\n",
    "        'num_leaves': (15, 35),\n",
    "        'colsample_bytree': (0.5, 0.8),\n",
    "        'reg_alpha': (0.1, 3),\n",
    "        'reg_lambda': (0.1, 3),\n",
    "        # 'min_split_gain': (0.001, 0.3),\n",
    "        'subsample': (0.5, 0.85),\n",
    "        'feature_fraction_bynode': (0.6, 0.85)\n",
    "    }\n",
    "\n",
    "    if not os.path.exists('Params_tunning/Log'):\n",
    "        os.makedirs('Params_tunning/Log')\n",
    "\n",
    "    optimizer = BayesianOptimization(f = CB_opt, pbounds = pbounds, verbose = 2, random_state = 209)\n",
    "    logger = JSONLogger(path=\"Params_tunning/Log/logs_{}.json\".format(i))\n",
    "    optimizer.subscribe(Events.OPTIMIZATION_STEP, logger)\n",
    "    optimizer.maximize(init_points = 5, n_iter = 15)\n",
    "\n",
    "    print(optimizer.max['target'])\n",
    "\n",
    "    max_bo_params = optimizer.max['params']\n",
    "\n",
    "    return max_bo_params"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "def get_bo_result(max_bo_params):\n",
    "    opt_params = {\n",
    "        'max_depth': round(max_bo_params['max_depth']),\n",
    "        'num_leaves': round(max_bo_params['num_leaves']),\n",
    "        'colsample_bytree': max_bo_params['colsample_bytree'],\n",
    "        'reg_alpha': max_bo_params['reg_alpha'],\n",
    "        'reg_lambda': max_bo_params['reg_lambda'],\n",
    "        'subsample': max_bo_params['subsample'],\n",
    "        'feature_fraction_bynode': max_bo_params['feature_fraction_bynode'],\n",
    "        'verbose': 0,\n",
    "        'n_estimators': 7999,\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'dart',\n",
    "        'learning_rate': 0.05,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "\n",
    "    return opt_params\n",
    "\n",
    "def get_best_params(path):\n",
    "    tmp = pd.read_json(path, lines=True)\n",
    "    max_t = 0\n",
    "    max_i = 0\n",
    "\n",
    "    for i in range(tmp.shape[0]):\n",
    "        line = tmp.loc[i, :]\n",
    "        t = line['target']\n",
    "\n",
    "        if t > max_t:\n",
    "            max_t = t\n",
    "            max_i = i\n",
    "\n",
    "    max_line = tmp.loc[max_i, :]\n",
    "    max_param = max_line['params']\n",
    "    max_param['max_depth'] = round(max_param['max_depth'])\n",
    "    max_param['num_leaves'] = round(max_param['num_leaves'])\n",
    "\n",
    "    return max_param"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "data": {
      "text/plain": "   index  lat       lon  startdate  contest-pevpr-sfc-gauss-14d__pevpr  \\\n0      0  0.0  0.833333 2014-09-01                              237.00   \n1      1  0.0  0.833333 2014-09-02                              228.90   \n2      2  0.0  0.833333 2014-09-03                              220.69   \n3      3  0.0  0.833333 2014-09-04                              225.28   \n4      4  0.0  0.833333 2014-09-05                              237.24   \n\n   nmme0-tmp2m-34w__cancm30  nmme0-tmp2m-34w__cancm40  \\\n0                     29.02                     31.64   \n1                     29.02                     31.64   \n2                     29.02                     31.64   \n3                     29.02                     31.64   \n4                     29.02                     31.64   \n\n   nmme0-tmp2m-34w__ccsm30  nmme0-tmp2m-34w__ccsm40  nmme0-tmp2m-34w__cfsv20  \\\n0                    29.62                    30.73                    29.71   \n1                    29.62                    30.73                    29.71   \n2                    29.62                    30.73                    29.71   \n3                    29.62                    30.73                    29.71   \n4                    29.62                    30.73                    29.71   \n\n   ...  nmme-prate-56w__cancm4_ewa  nmme-prate-56w__ccsm3_ewa  \\\n0  ...                       18.36                      10.39   \n1  ...                       18.36                      10.39   \n2  ...                       18.36                      10.39   \n3  ...                       18.36                      10.39   \n4  ...                       18.36                      10.39   \n\n   nmme-prate-56w__ccsm4_ewa  nmme-prate-56w__cfsv2_ewa  \\\n0                       35.4                      34.54   \n1                       35.4                      34.54   \n2                       35.4                      34.54   \n3                       35.4                      34.54   \n4                       35.4                      34.54   \n\n   nmme-prate-56w__gfdl_ewa  nmme-prate-56w__gfdlflora_ewa  \\\n0                     19.54                          35.99   \n1                     19.54                          35.99   \n2                     19.54                          35.99   \n3                     19.54                          35.99   \n4                     19.54                          35.99   \n\n   nmme-prate-56w__gfdlflorb_ewa  nmme-prate-56w__nasa_ewa  \\\n0                          28.31                     18.89   \n1                          28.31                     18.89   \n2                          28.31                     18.89   \n3                          28.31                     18.89   \n4                          28.31                     18.89   \n\n   nmme-prate-56w__nmmemean_ewa  final_target  \n0                         24.43  0.0_0.8333_7  \n1                         24.43  0.0_0.8333_7  \n2                         24.43  0.0_0.8333_7  \n3                         24.43  0.0_0.8333_7  \n4                         24.43  0.0_0.8333_7  \n\n[5 rows x 1061 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>lat</th>\n      <th>lon</th>\n      <th>startdate</th>\n      <th>contest-pevpr-sfc-gauss-14d__pevpr</th>\n      <th>nmme0-tmp2m-34w__cancm30</th>\n      <th>nmme0-tmp2m-34w__cancm40</th>\n      <th>nmme0-tmp2m-34w__ccsm30</th>\n      <th>nmme0-tmp2m-34w__ccsm40</th>\n      <th>nmme0-tmp2m-34w__cfsv20</th>\n      <th>...</th>\n      <th>nmme-prate-56w__cancm4_ewa</th>\n      <th>nmme-prate-56w__ccsm3_ewa</th>\n      <th>nmme-prate-56w__ccsm4_ewa</th>\n      <th>nmme-prate-56w__cfsv2_ewa</th>\n      <th>nmme-prate-56w__gfdl_ewa</th>\n      <th>nmme-prate-56w__gfdlflora_ewa</th>\n      <th>nmme-prate-56w__gfdlflorb_ewa</th>\n      <th>nmme-prate-56w__nasa_ewa</th>\n      <th>nmme-prate-56w__nmmemean_ewa</th>\n      <th>final_target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.833333</td>\n      <td>2014-09-01</td>\n      <td>237.00</td>\n      <td>29.02</td>\n      <td>31.64</td>\n      <td>29.62</td>\n      <td>30.73</td>\n      <td>29.71</td>\n      <td>...</td>\n      <td>18.36</td>\n      <td>10.39</td>\n      <td>35.4</td>\n      <td>34.54</td>\n      <td>19.54</td>\n      <td>35.99</td>\n      <td>28.31</td>\n      <td>18.89</td>\n      <td>24.43</td>\n      <td>0.0_0.8333_7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.833333</td>\n      <td>2014-09-02</td>\n      <td>228.90</td>\n      <td>29.02</td>\n      <td>31.64</td>\n      <td>29.62</td>\n      <td>30.73</td>\n      <td>29.71</td>\n      <td>...</td>\n      <td>18.36</td>\n      <td>10.39</td>\n      <td>35.4</td>\n      <td>34.54</td>\n      <td>19.54</td>\n      <td>35.99</td>\n      <td>28.31</td>\n      <td>18.89</td>\n      <td>24.43</td>\n      <td>0.0_0.8333_7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.833333</td>\n      <td>2014-09-03</td>\n      <td>220.69</td>\n      <td>29.02</td>\n      <td>31.64</td>\n      <td>29.62</td>\n      <td>30.73</td>\n      <td>29.71</td>\n      <td>...</td>\n      <td>18.36</td>\n      <td>10.39</td>\n      <td>35.4</td>\n      <td>34.54</td>\n      <td>19.54</td>\n      <td>35.99</td>\n      <td>28.31</td>\n      <td>18.89</td>\n      <td>24.43</td>\n      <td>0.0_0.8333_7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.833333</td>\n      <td>2014-09-04</td>\n      <td>225.28</td>\n      <td>29.02</td>\n      <td>31.64</td>\n      <td>29.62</td>\n      <td>30.73</td>\n      <td>29.71</td>\n      <td>...</td>\n      <td>18.36</td>\n      <td>10.39</td>\n      <td>35.4</td>\n      <td>34.54</td>\n      <td>19.54</td>\n      <td>35.99</td>\n      <td>28.31</td>\n      <td>18.89</td>\n      <td>24.43</td>\n      <td>0.0_0.8333_7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.0</td>\n      <td>0.833333</td>\n      <td>2014-09-05</td>\n      <td>237.24</td>\n      <td>29.02</td>\n      <td>31.64</td>\n      <td>29.62</td>\n      <td>30.73</td>\n      <td>29.71</td>\n      <td>...</td>\n      <td>18.36</td>\n      <td>10.39</td>\n      <td>35.4</td>\n      <td>34.54</td>\n      <td>19.54</td>\n      <td>35.99</td>\n      <td>28.31</td>\n      <td>18.89</td>\n      <td>24.43</td>\n      <td>0.0_0.8333_7</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 1061 columns</p>\n</div>"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_bins = 8\n",
    "\n",
    "df_month_9_10 = df_train[(df_train.startdate.dt.month == 9) | (df_train.startdate.dt.month == 10)]\n",
    "# df_month_9_10 = df_train[((df_train.startdate >= '2015-08-15') & (df_train.startdate <= '2015-11-14')) | (df_train.startdate >= '2014-08-15') & (df_train.startdate <= '2014-11-14')]\n",
    "df_month_9_10.loc[:, 'bin'] = pd.qcut(df_month_9_10[target_], q=no_bins, labels=range(no_bins))\n",
    "df_month_9_10['final_target'] = df_month_9_10['idx'] + '_' + df_month_9_10['bin'].astype('str')\n",
    "df_month_9_10.drop(columns=['idx', 'bin'], inplace=True)\n",
    "df_month_9_10.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "df_train.drop(columns='idx', inplace=True)\n",
    "df_test.drop(columns='idx', inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "print([item for item, count in collections.Counter(df_train.columns).items() if count > 1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "dict_result = {}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - 0\n",
      "Pre-processing...\n",
      "Tuning...\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.938459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Take time:  2045.5411028862\n",
      "Train_score: 0.2067729797299457  Valid_score: 0.4230468450869058\n",
      "-------------\n",
      "Training - 1\n",
      "Pre-processing...\n",
      "Tuning...\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.978327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Take time:  1964.688716173172\n",
      "Train_score: 0.2069605282229833  Valid_score: 0.3531584604016671\n",
      "-------------\n",
      "Training - 2\n",
      "Pre-processing...\n",
      "Tuning...\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.033995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Take time:  1915.1813492774963\n",
      "Train_score: 0.2066243873654638  Valid_score: 0.3151226725677582\n",
      "-------------\n",
      "Training - 3\n",
      "Pre-processing...\n",
      "Tuning...\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.914025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Take time:  1975.2590651512146\n",
      "Train_score: 0.20746151016196496  Valid_score: 0.3104984826511482\n",
      "-------------\n",
      "Training - 4\n",
      "Pre-processing...\n",
      "Tuning...\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.933290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Take time:  1895.893362045288\n",
      "Train_score: 0.20729903115290554  Valid_score: 0.35109714240743733\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "X = df_month_9_10.copy()\n",
    "y = df_month_9_10['final_target']\n",
    "\n",
    "X.drop(columns='final_target', inplace=True)\n",
    "df_month_9_10.drop(columns='final_target', inplace=True)\n",
    "\n",
    "df_train = df_train[~((df_train.startdate.dt.month == 9) | (df_train.startdate.dt.month == 10))]\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    t = time.time()\n",
    "\n",
    "    print(\"Training - {}\".format(i))\n",
    "\n",
    "    if i not in dict_result:\n",
    "        print('Pre-processing...')\n",
    "\n",
    "        X_train_fold = df_month_9_10.iloc[train_index]\n",
    "        X_valid = df_month_9_10.iloc[test_index]\n",
    "\n",
    "        X_train = pd.concat([df_train, X_train_fold])\n",
    "        y_train = X_train[target_]\n",
    "        y_valid = X_valid[target_]\n",
    "        X_train.drop(columns=target_, inplace=True)\n",
    "        X_valid.drop(columns=target_, inplace=True)\n",
    "\n",
    "        test_index = df_test[\"index\"].values\n",
    "        X_test = df_test.copy()\n",
    "\n",
    "        cat_cols = [i for i in X_train.select_dtypes(include='object').columns if i != date_col]\n",
    "        X_train, X1, listEncoder = handle_feature_train_data(X_train, date_col, cat_cols.copy())\n",
    "        X_valid = handle_feature_test_data(X_valid, listEncoder, columns_cat=cat_cols.copy())\n",
    "        X_test = handle_feature_test_data(X_test, listEncoder, columns_cat=cat_cols.copy())\n",
    "\n",
    "        drop_mei = [each for each in X_train.columns if \"mei\" in each]\n",
    "        drop_ = [*drop_col, *[\"month\", \"day_of_year\", \"day_of_year_sin\", \"day_of_year_cos\", \"month_sin\", \"month_cos\", \"index\"], *drop_mei, *col_drift]\n",
    "        X_train = X_train.drop(columns=drop_)\n",
    "        X_valid = X_valid.drop(columns=drop_)\n",
    "        X_test = X_test.drop(columns=drop_)\n",
    "\n",
    "        # X_train = X_train.drop(columns=target_)\n",
    "        # X_valid = X_valid.drop(columns=target_)\n",
    "\n",
    "        # Model\n",
    "        print('Tuning...')\n",
    "\n",
    "        # max_bo_params = bayes_tunning()\n",
    "        # opt_params = get_bo_result(max_bo_params)\n",
    "\n",
    "        opt_params = {\n",
    "            'colsample_bytree': 0.7128556340156371,\n",
    "            'feature_fraction_bynode': 0.7786840214424174,\n",
    "            'max_depth': 13,\n",
    "            'num_leaves': 14,\n",
    "            'reg_alpha': 3.9,\n",
    "            'reg_lambda': 1.665865282736549,\n",
    "            'subsample': 0.6693424140753386,\n",
    "            'metric': 'rmse',\n",
    "            'n_estimators': 7999,\n",
    "            'boosting_type': 'dart',\n",
    "            'verbose': 0\n",
    "        }\n",
    "\n",
    "        reg = LGBMRegressor(**opt_params)\n",
    "\n",
    "        reg.fit(X_train, y_train,\n",
    "                eval_metric='rmse',\n",
    "                categorical_feature=[\n",
    "                    *['climateregions__climateregion', 'idx', 'mjo1d__phase'],\n",
    "                    *[each + \"_bin\" for each in bin_col]\n",
    "                ])\n",
    "\n",
    "        ypred_train = reg.predict(X_train)\n",
    "        ypred_valid = reg.predict(X_valid)\n",
    "\n",
    "        result_train = mean_squared_error(y_train, ypred_train, squared=False)\n",
    "        result_valid = mean_squared_error(y_valid, ypred_valid, squared=False)\n",
    "\n",
    "        print(\"Take time: \", time.time() - t)\n",
    "        print(\"Train_score: {}  Valid_score: {}\".format(result_train, result_valid))\n",
    "\n",
    "        ypred_test = reg.predict(X_test)\n",
    "        dict_result[i] = ypred_test\n",
    "\n",
    "    else:\n",
    "        print('Fold was trained!')\n",
    "\n",
    "    print(\"-------------\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "ypred_test = np.mean([value for key, value in dict_result.items()], axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "pd.DataFrame(data = {\"{}\".format(target_): ypred_test, \"index\": test_index}).to_csv(\"submit_lgbm_bo.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "data": {
      "text/plain": "(363193, 1000)"
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "data": {
      "text/plain": "                                        col    imp\n999                                     idx  25529\n56      contest-wind-h500-14d__wind-hgt-500   6689\n37                     contest-slp-14d__slp   3956\n186                nmme-tmp2m-56w__nasa_bin   3853\n3        contest-pevpr-sfc-gauss-14d__pevpr   3416\n..                                      ...    ...\n827  nmme0-prate-34w__cancm40_rolling_std_3      0\n828   nmme0-prate-34w__ccsm30_rolling_std_3      0\n829   nmme0-prate-34w__ccsm40_rolling_std_3      0\n830   nmme0-prate-34w__cfsv20_rolling_std_3      0\n696      wind-vwnd-250-2010-5_rolling_std_3      0\n\n[1000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col</th>\n      <th>imp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>999</th>\n      <td>idx</td>\n      <td>25529</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>contest-wind-h500-14d__wind-hgt-500</td>\n      <td>6689</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>contest-slp-14d__slp</td>\n      <td>3956</td>\n    </tr>\n    <tr>\n      <th>186</th>\n      <td>nmme-tmp2m-56w__nasa_bin</td>\n      <td>3853</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>contest-pevpr-sfc-gauss-14d__pevpr</td>\n      <td>3416</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>827</th>\n      <td>nmme0-prate-34w__cancm40_rolling_std_3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>828</th>\n      <td>nmme0-prate-34w__ccsm30_rolling_std_3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>829</th>\n      <td>nmme0-prate-34w__ccsm40_rolling_std_3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>830</th>\n      <td>nmme0-prate-34w__cfsv20_rolling_std_3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>696</th>\n      <td>wind-vwnd-250-2010-5_rolling_std_3</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = reg.feature_importances_\n",
    "\n",
    "data = {'col': X_train.columns, 'imp': importances}\n",
    "\n",
    "ft_imp_df = pd.DataFrame(data)\n",
    "ft_imp_df.sort_values('imp', ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ft_imp_df[]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "data": {
      "text/plain": "1000"
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(X_train.columns))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "ft_imp_df.to_csv('ft_imp.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ensemble"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "outputs": [
    {
     "data": {
      "text/plain": "   contest-tmp2m-14d__tmp2m   index\n0                 28.739887  375734\n1                 28.698812  375735\n2                 28.734199  375736\n3                 28.808007  375737\n4                 28.838081  375738",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>contest-tmp2m-14d__tmp2m</th>\n      <th>index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>28.739887</td>\n      <td>375734</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28.698812</td>\n      <td>375735</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28.734199</td>\n      <td>375736</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>28.808007</td>\n      <td>375737</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28.838081</td>\n      <td>375738</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_tunning_1 = pd.read_csv('submit_lgbm.csv')\n",
    "\n",
    "submit_lgbm = pd.read_csv('submit_lgbm_bo.csv')\n",
    "\n",
    "submit_res = pd.read_csv('submit_res.csv')\n",
    "\n",
    "submit_lgbm.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "outputs": [],
   "source": [
    "submit_ensemple = pd.DataFrame()\n",
    "\n",
    "submit_ensemple[target_] = (submit_lgbm[target_] + submit_tunning_1[target_] + submit_res[target_]) / 3\n",
    "submit_ensemple['index'] = submit_lgbm['index']\n",
    "\n",
    "submit_ensemple.to_csv('submit_ensemble.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [
    {
     "data": {
      "text/plain": "       contest-tmp2m-14d__tmp2m   index\n31304                 13.672541  407038\n31305                 13.514550  407039\n31306                 13.787864  407040\n31307                 13.753263  407041\n31308                 13.521520  407042\n31309                 13.445884  407043\n31310                 13.556410  407044\n31311                 13.210343  407045\n31312                 13.428071  407046\n31313                 13.390244  407047\n31314                 13.488916  407048\n31315                 13.455805  407049\n31316                 12.802218  407050\n31317                 11.804092  407051\n31318                 11.018255  407052\n31319                 10.934590  407053\n31320                 10.533856  407054\n31321                  9.652723  407055\n31322                  9.081522  407056\n31323                  8.617228  407057\n31324                  8.379195  407058\n31325                  7.954469  407059\n31326                  7.581502  407060\n31327                  6.746321  407061\n31328                  5.952988  407062\n31329                  5.503757  407063\n31330                  5.754187  407064\n31331                  5.947866  407065\n31332                  5.717441  407066\n31333                  5.240797  407067\n31334                  5.400370  407068\n31335                  5.836459  407069\n31336                  6.080840  407070\n31337                  6.015500  407071\n31338                  5.355915  407072\n31339                  5.056346  407073\n31340                  4.769066  407074\n31341                  4.720264  407075\n31342                  4.830033  407076\n31343                  4.979740  407077\n31344                  4.831228  407078\n31345                  4.828707  407079\n31346                  5.188029  407080\n31347                  5.508628  407081\n31348                  5.510562  407082\n31349                  5.864299  407083\n31350                  6.005344  407084\n31351                  5.401119  407085\n31352                  5.752542  407086\n31353                  6.033435  407087",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>contest-tmp2m-14d__tmp2m</th>\n      <th>index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>31304</th>\n      <td>13.672541</td>\n      <td>407038</td>\n    </tr>\n    <tr>\n      <th>31305</th>\n      <td>13.514550</td>\n      <td>407039</td>\n    </tr>\n    <tr>\n      <th>31306</th>\n      <td>13.787864</td>\n      <td>407040</td>\n    </tr>\n    <tr>\n      <th>31307</th>\n      <td>13.753263</td>\n      <td>407041</td>\n    </tr>\n    <tr>\n      <th>31308</th>\n      <td>13.521520</td>\n      <td>407042</td>\n    </tr>\n    <tr>\n      <th>31309</th>\n      <td>13.445884</td>\n      <td>407043</td>\n    </tr>\n    <tr>\n      <th>31310</th>\n      <td>13.556410</td>\n      <td>407044</td>\n    </tr>\n    <tr>\n      <th>31311</th>\n      <td>13.210343</td>\n      <td>407045</td>\n    </tr>\n    <tr>\n      <th>31312</th>\n      <td>13.428071</td>\n      <td>407046</td>\n    </tr>\n    <tr>\n      <th>31313</th>\n      <td>13.390244</td>\n      <td>407047</td>\n    </tr>\n    <tr>\n      <th>31314</th>\n      <td>13.488916</td>\n      <td>407048</td>\n    </tr>\n    <tr>\n      <th>31315</th>\n      <td>13.455805</td>\n      <td>407049</td>\n    </tr>\n    <tr>\n      <th>31316</th>\n      <td>12.802218</td>\n      <td>407050</td>\n    </tr>\n    <tr>\n      <th>31317</th>\n      <td>11.804092</td>\n      <td>407051</td>\n    </tr>\n    <tr>\n      <th>31318</th>\n      <td>11.018255</td>\n      <td>407052</td>\n    </tr>\n    <tr>\n      <th>31319</th>\n      <td>10.934590</td>\n      <td>407053</td>\n    </tr>\n    <tr>\n      <th>31320</th>\n      <td>10.533856</td>\n      <td>407054</td>\n    </tr>\n    <tr>\n      <th>31321</th>\n      <td>9.652723</td>\n      <td>407055</td>\n    </tr>\n    <tr>\n      <th>31322</th>\n      <td>9.081522</td>\n      <td>407056</td>\n    </tr>\n    <tr>\n      <th>31323</th>\n      <td>8.617228</td>\n      <td>407057</td>\n    </tr>\n    <tr>\n      <th>31324</th>\n      <td>8.379195</td>\n      <td>407058</td>\n    </tr>\n    <tr>\n      <th>31325</th>\n      <td>7.954469</td>\n      <td>407059</td>\n    </tr>\n    <tr>\n      <th>31326</th>\n      <td>7.581502</td>\n      <td>407060</td>\n    </tr>\n    <tr>\n      <th>31327</th>\n      <td>6.746321</td>\n      <td>407061</td>\n    </tr>\n    <tr>\n      <th>31328</th>\n      <td>5.952988</td>\n      <td>407062</td>\n    </tr>\n    <tr>\n      <th>31329</th>\n      <td>5.503757</td>\n      <td>407063</td>\n    </tr>\n    <tr>\n      <th>31330</th>\n      <td>5.754187</td>\n      <td>407064</td>\n    </tr>\n    <tr>\n      <th>31331</th>\n      <td>5.947866</td>\n      <td>407065</td>\n    </tr>\n    <tr>\n      <th>31332</th>\n      <td>5.717441</td>\n      <td>407066</td>\n    </tr>\n    <tr>\n      <th>31333</th>\n      <td>5.240797</td>\n      <td>407067</td>\n    </tr>\n    <tr>\n      <th>31334</th>\n      <td>5.400370</td>\n      <td>407068</td>\n    </tr>\n    <tr>\n      <th>31335</th>\n      <td>5.836459</td>\n      <td>407069</td>\n    </tr>\n    <tr>\n      <th>31336</th>\n      <td>6.080840</td>\n      <td>407070</td>\n    </tr>\n    <tr>\n      <th>31337</th>\n      <td>6.015500</td>\n      <td>407071</td>\n    </tr>\n    <tr>\n      <th>31338</th>\n      <td>5.355915</td>\n      <td>407072</td>\n    </tr>\n    <tr>\n      <th>31339</th>\n      <td>5.056346</td>\n      <td>407073</td>\n    </tr>\n    <tr>\n      <th>31340</th>\n      <td>4.769066</td>\n      <td>407074</td>\n    </tr>\n    <tr>\n      <th>31341</th>\n      <td>4.720264</td>\n      <td>407075</td>\n    </tr>\n    <tr>\n      <th>31342</th>\n      <td>4.830033</td>\n      <td>407076</td>\n    </tr>\n    <tr>\n      <th>31343</th>\n      <td>4.979740</td>\n      <td>407077</td>\n    </tr>\n    <tr>\n      <th>31344</th>\n      <td>4.831228</td>\n      <td>407078</td>\n    </tr>\n    <tr>\n      <th>31345</th>\n      <td>4.828707</td>\n      <td>407079</td>\n    </tr>\n    <tr>\n      <th>31346</th>\n      <td>5.188029</td>\n      <td>407080</td>\n    </tr>\n    <tr>\n      <th>31347</th>\n      <td>5.508628</td>\n      <td>407081</td>\n    </tr>\n    <tr>\n      <th>31348</th>\n      <td>5.510562</td>\n      <td>407082</td>\n    </tr>\n    <tr>\n      <th>31349</th>\n      <td>5.864299</td>\n      <td>407083</td>\n    </tr>\n    <tr>\n      <th>31350</th>\n      <td>6.005344</td>\n      <td>407084</td>\n    </tr>\n    <tr>\n      <th>31351</th>\n      <td>5.401119</td>\n      <td>407085</td>\n    </tr>\n    <tr>\n      <th>31352</th>\n      <td>5.752542</td>\n      <td>407086</td>\n    </tr>\n    <tr>\n      <th>31353</th>\n      <td>6.033435</td>\n      <td>407087</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_res.tail(50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "outputs": [
    {
     "data": {
      "text/plain": "       contest-tmp2m-14d__tmp2m   index\n31304                 13.671254  407038\n31305                 13.526216  407039\n31306                 13.751920  407040\n31307                 13.707600  407041\n31308                 13.472247  407042\n31309                 13.385757  407043\n31310                 13.520935  407044\n31311                 13.129234  407045\n31312                 13.351761  407046\n31313                 13.348171  407047\n31314                 13.427183  407048\n31315                 13.372659  407049\n31316                 12.719125  407050\n31317                 11.706524  407051\n31318                 10.819025  407052\n31319                 10.732648  407053\n31320                 10.383004  407054\n31321                  9.485247  407055\n31322                  8.875910  407056\n31323                  8.587678  407057\n31324                  8.359546  407058\n31325                  8.002799  407059\n31326                  7.699969  407060\n31327                  6.907625  407061\n31328                  6.068382  407062\n31329                  5.552452  407063\n31330                  5.799655  407064\n31331                  6.058895  407065\n31332                  5.867223  407066\n31333                  5.427754  407067\n31334                  5.574418  407068\n31335                  6.008796  407069\n31336                  6.302630  407070\n31337                  6.263622  407071\n31338                  5.618415  407072\n31339                  5.257869  407073\n31340                  5.014809  407074\n31341                  4.935566  407075\n31342                  5.000946  407076\n31343                  5.107586  407077\n31344                  4.977653  407078\n31345                  4.985258  407079\n31346                  5.354801  407080\n31347                  5.726643  407081\n31348                  5.706792  407082\n31349                  6.054954  407083\n31350                  6.220385  407084\n31351                  5.571826  407085\n31352                  5.793874  407086\n31353                  6.133805  407087",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>contest-tmp2m-14d__tmp2m</th>\n      <th>index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>31304</th>\n      <td>13.671254</td>\n      <td>407038</td>\n    </tr>\n    <tr>\n      <th>31305</th>\n      <td>13.526216</td>\n      <td>407039</td>\n    </tr>\n    <tr>\n      <th>31306</th>\n      <td>13.751920</td>\n      <td>407040</td>\n    </tr>\n    <tr>\n      <th>31307</th>\n      <td>13.707600</td>\n      <td>407041</td>\n    </tr>\n    <tr>\n      <th>31308</th>\n      <td>13.472247</td>\n      <td>407042</td>\n    </tr>\n    <tr>\n      <th>31309</th>\n      <td>13.385757</td>\n      <td>407043</td>\n    </tr>\n    <tr>\n      <th>31310</th>\n      <td>13.520935</td>\n      <td>407044</td>\n    </tr>\n    <tr>\n      <th>31311</th>\n      <td>13.129234</td>\n      <td>407045</td>\n    </tr>\n    <tr>\n      <th>31312</th>\n      <td>13.351761</td>\n      <td>407046</td>\n    </tr>\n    <tr>\n      <th>31313</th>\n      <td>13.348171</td>\n      <td>407047</td>\n    </tr>\n    <tr>\n      <th>31314</th>\n      <td>13.427183</td>\n      <td>407048</td>\n    </tr>\n    <tr>\n      <th>31315</th>\n      <td>13.372659</td>\n      <td>407049</td>\n    </tr>\n    <tr>\n      <th>31316</th>\n      <td>12.719125</td>\n      <td>407050</td>\n    </tr>\n    <tr>\n      <th>31317</th>\n      <td>11.706524</td>\n      <td>407051</td>\n    </tr>\n    <tr>\n      <th>31318</th>\n      <td>10.819025</td>\n      <td>407052</td>\n    </tr>\n    <tr>\n      <th>31319</th>\n      <td>10.732648</td>\n      <td>407053</td>\n    </tr>\n    <tr>\n      <th>31320</th>\n      <td>10.383004</td>\n      <td>407054</td>\n    </tr>\n    <tr>\n      <th>31321</th>\n      <td>9.485247</td>\n      <td>407055</td>\n    </tr>\n    <tr>\n      <th>31322</th>\n      <td>8.875910</td>\n      <td>407056</td>\n    </tr>\n    <tr>\n      <th>31323</th>\n      <td>8.587678</td>\n      <td>407057</td>\n    </tr>\n    <tr>\n      <th>31324</th>\n      <td>8.359546</td>\n      <td>407058</td>\n    </tr>\n    <tr>\n      <th>31325</th>\n      <td>8.002799</td>\n      <td>407059</td>\n    </tr>\n    <tr>\n      <th>31326</th>\n      <td>7.699969</td>\n      <td>407060</td>\n    </tr>\n    <tr>\n      <th>31327</th>\n      <td>6.907625</td>\n      <td>407061</td>\n    </tr>\n    <tr>\n      <th>31328</th>\n      <td>6.068382</td>\n      <td>407062</td>\n    </tr>\n    <tr>\n      <th>31329</th>\n      <td>5.552452</td>\n      <td>407063</td>\n    </tr>\n    <tr>\n      <th>31330</th>\n      <td>5.799655</td>\n      <td>407064</td>\n    </tr>\n    <tr>\n      <th>31331</th>\n      <td>6.058895</td>\n      <td>407065</td>\n    </tr>\n    <tr>\n      <th>31332</th>\n      <td>5.867223</td>\n      <td>407066</td>\n    </tr>\n    <tr>\n      <th>31333</th>\n      <td>5.427754</td>\n      <td>407067</td>\n    </tr>\n    <tr>\n      <th>31334</th>\n      <td>5.574418</td>\n      <td>407068</td>\n    </tr>\n    <tr>\n      <th>31335</th>\n      <td>6.008796</td>\n      <td>407069</td>\n    </tr>\n    <tr>\n      <th>31336</th>\n      <td>6.302630</td>\n      <td>407070</td>\n    </tr>\n    <tr>\n      <th>31337</th>\n      <td>6.263622</td>\n      <td>407071</td>\n    </tr>\n    <tr>\n      <th>31338</th>\n      <td>5.618415</td>\n      <td>407072</td>\n    </tr>\n    <tr>\n      <th>31339</th>\n      <td>5.257869</td>\n      <td>407073</td>\n    </tr>\n    <tr>\n      <th>31340</th>\n      <td>5.014809</td>\n      <td>407074</td>\n    </tr>\n    <tr>\n      <th>31341</th>\n      <td>4.935566</td>\n      <td>407075</td>\n    </tr>\n    <tr>\n      <th>31342</th>\n      <td>5.000946</td>\n      <td>407076</td>\n    </tr>\n    <tr>\n      <th>31343</th>\n      <td>5.107586</td>\n      <td>407077</td>\n    </tr>\n    <tr>\n      <th>31344</th>\n      <td>4.977653</td>\n      <td>407078</td>\n    </tr>\n    <tr>\n      <th>31345</th>\n      <td>4.985258</td>\n      <td>407079</td>\n    </tr>\n    <tr>\n      <th>31346</th>\n      <td>5.354801</td>\n      <td>407080</td>\n    </tr>\n    <tr>\n      <th>31347</th>\n      <td>5.726643</td>\n      <td>407081</td>\n    </tr>\n    <tr>\n      <th>31348</th>\n      <td>5.706792</td>\n      <td>407082</td>\n    </tr>\n    <tr>\n      <th>31349</th>\n      <td>6.054954</td>\n      <td>407083</td>\n    </tr>\n    <tr>\n      <th>31350</th>\n      <td>6.220385</td>\n      <td>407084</td>\n    </tr>\n    <tr>\n      <th>31351</th>\n      <td>5.571826</td>\n      <td>407085</td>\n    </tr>\n    <tr>\n      <th>31352</th>\n      <td>5.793874</td>\n      <td>407086</td>\n    </tr>\n    <tr>\n      <th>31353</th>\n      <td>6.133805</td>\n      <td>407087</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_ensemple.tail(50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class TargetEncoder(base.BaseEstimator,base.TransformerMixin):\n",
    "    def __init__(self, colnames, targetName, colSupport=None,\n",
    "                  discardOriginal_col=False):\n",
    "        self.colnames = colnames\n",
    "        self.colSupport = colSupport\n",
    "        self.targetName = targetName\n",
    "        self.discardOriginal_col = discardOriginal_col\n",
    "        self.new_cols = colnames + '_tar'\n",
    "        self.data_transform = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.colSupport != None:\n",
    "            self.data_transform = X.groupby([self.colnames, self.colSupport]).agg({self.targetName: 'mean'}).rename(columns={self.targetName: self.new_cols})\n",
    "        else:\n",
    "            self.data_transform = X.groupby([self.colnames]).agg({self.targetName: 'mean'}).rename(columns={self.targetName: self.new_cols})\n",
    "        return self\n",
    "\n",
    "    def transform(self, X,train=True):\n",
    "        X = X.merge(self.data_transform.reset_index())\n",
    "        encoded_feature = X[self.new_cols].values\n",
    "        if train:\n",
    "            print('Correlation between the new feature, {} and, {} is {}.'.format(self.new_cols,self.targetName,\n",
    "                   ma.corrcoef(ma.masked_invalid(X[self.targetName].values), ma.masked_invalid(encoded_feature))[0][1]))\n",
    "        if self.discardOriginal_col:\n",
    "            X = X.drop(self.targetName, axis=1)\n",
    "        return X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dict_result = {}\n",
    "year_valid = [2015, 2015, 2015, 2015, 2015, 2015, 2016, 2016, 2016, 2016]\n",
    "month_valid = [1, 3, 5, 7, 9, 11, 1, 3, 5, 7]\n",
    "gap = 1\n",
    "\n",
    "for index in range(len(year_valid)):\n",
    "    if index in dict_result:\n",
    "        continue\n",
    "    y, m_s, m_e = year_valid[index], month_valid[index], month_valid[index] + 1\n",
    "    X_valid = df_train[(df_train[date_col].dt.year == y) & (df_train[date_col].dt.month >= m_s) & (df_train[date_col].dt.month <= m_e)]\n",
    "    X_train = df_train[~((df_train[date_col].dt.year == y) & (df_train[date_col].dt.month >= m_s) & (df_train[date_col].dt.month <= m_e))]\n",
    "\n",
    "    # y_train = X_train[target_].copy()\n",
    "    X_train = X_train.drop(columns=[\"index\"])\n",
    "    # y_valid = X_valid[target_].copy()\n",
    "    X_valid = X_valid.drop(columns=[\"index\"])\n",
    "\n",
    "    test_index = df_test[\"index\"].values\n",
    "    X_test = df_test.drop(columns=[\"index\"]).copy()\n",
    "\n",
    "    cat_cols = [i for i in X_train.select_dtypes(include='object').columns if i != date_col]\n",
    "    X_train, listEncoder, df_mean = handle_feature_train_data(X_train, date_col, cat_cols.copy())\n",
    "    X_valid = handle_feature_test_data(X_valid, listEncoder, df_mean, columns_cat=cat_cols.copy())\n",
    "    X_test = handle_feature_test_data(X_test, listEncoder, df_mean, columns_cat=cat_cols.copy())\n",
    "\n",
    "    target_climate = TargetEncoder(colnames='climateregions__climateregion', targetName=target_).fit(X_train)\n",
    "    target_idx = TargetEncoder(colnames='idx', targetName=target_).fit(X_train)\n",
    "\n",
    "    X_train = target_climate.transform(X_train)\n",
    "    X_valid = target_climate.transform(X_valid)\n",
    "    X_test = target_climate.transform(X_test, train=False)\n",
    "    X_train = target_idx.transform(X_train)\n",
    "    X_valid = target_idx.transform(X_valid)\n",
    "    X_test = target_idx.transform(X_test, train=False)\n",
    "\n",
    "    y_train = X_train[target_].copy()\n",
    "    y_valid = X_valid[target_].copy()\n",
    "    X_train = X_train.drop(columns=[target_])\n",
    "    X_valid = X_valid.drop(columns=[target_])\n",
    "\n",
    "    drop_ = [*drop_col, *[\"mei__nip\", \"idx\", \"climateregions__climateregion\", 'month', 'year'], *[col for col in X_train.columns if 'Unnamed' in col]]\n",
    "    # drop_ = [\"month\", \"day_of_year\", \"day_of_year_sin\", \"day_of_year_cos\", \"month_sin\", \"month_cos\", \"mei__nip\"]\n",
    "\n",
    "    X_train_ = X_train.drop(columns=drop_)\n",
    "    X_valid_ = X_valid.drop(columns=drop_)\n",
    "    X_test_ = X_test.drop(columns=drop_)\n",
    "\n",
    "    print(\"Training - {}\".format(index))\n",
    "\n",
    "    t = time.time()\n",
    "    lgb = LinearRegression(normalize=True)\n",
    "    lgb.fit(X_train_, y_train)\n",
    "    print(\"Take time: \", time.time() - t)\n",
    "\n",
    "    ypred_test = lgb.predict(X_test_)\n",
    "    dict_result[index] = ypred_test\n",
    "\n",
    "    result_valid_ = mean_squared_error(y_valid, lgb.predict(X_valid_), squared=False)\n",
    "    print(result_valid_)\n",
    "    print('-----------------')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ypred_test = np.mean([value for key, value in dict_result.items()], axis=0)\n",
    "pd.DataFrame(data = {\"{}\".format(target_): ypred_test, \"index\": test_index}).to_csv(\"submit_linear.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ridge"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dict_result1 = {}\n",
    "\n",
    "year_valid = [2015, 2015, 2015, 2015, 2015, 2015, 2016, 2016, 2016, 2016]\n",
    "month_valid = [1, 3, 5, 7, 9, 11, 1, 3, 5, 7]\n",
    "\n",
    "for index in range(len(year_valid)):\n",
    "    t = time.time()\n",
    "\n",
    "    if index in dict_result1:\n",
    "        continue\n",
    "    y, m_s, m_e = year_valid[index], month_valid[index], month_valid[index] + 1\n",
    "\n",
    "    print(\"Training - {}\".format(index))\n",
    "    print(f'Test on month {m_s} and {m_e}, year {y}')\n",
    "\n",
    "    X_valid = df_train[(df_train[date_col].dt.year == y) & (df_train[date_col].dt.month >= m_s) & (df_train[date_col].dt.month <= m_e)]\n",
    "    X_train = df_train[~((df_train[date_col].dt.year == y) & (df_train[date_col].dt.month >= m_s) & (df_train[date_col].dt.month <= m_e))]\n",
    "\n",
    "    y_train = X_train[target_]\n",
    "    y_valid = X_valid[target_]\n",
    "\n",
    "    date = np.array(X_valid['startdate'])\n",
    "\n",
    "    test_index = df_test[\"index\"].values\n",
    "    X_test = df_test.copy()\n",
    "\n",
    "    cat_cols = [i for i in X_train.select_dtypes(include='object').columns if i != date_col]\n",
    "    X_train, listEncoder, df_mean = handle_feature_train_data(X_train, date_col, cat_cols.copy())\n",
    "    X_valid = handle_feature_test_data(X_valid, listEncoder, df_mean, columns_cat=cat_cols.copy())\n",
    "    X_test = handle_feature_test_data(X_test, listEncoder, df_mean, columns_cat=cat_cols.copy())\n",
    "\n",
    "    drop_ = [*drop_col, *[col for col in X_train.columns if 'Unnamed' in col]]\n",
    "    # drop_ = [col for col in X_train.columns if 'Unnamed' in col]\n",
    "    X_train = X_train.drop(columns=drop_)\n",
    "    X_valid = X_valid.drop(columns=drop_)\n",
    "    X_test = X_test.drop(columns=drop_)\n",
    "\n",
    "    X_train = X_train.drop(columns=target_)\n",
    "    X_valid = X_valid.drop(columns=target_)\n",
    "\n",
    "    reg1 = Ridge(alpha=1)\n",
    "    reg1.fit(X_train, y_train)\n",
    "\n",
    "    ypred_train1 = reg1.predict(X_train)\n",
    "    ypred_valid1 = reg1.predict(X_valid)\n",
    "\n",
    "    result_train = mean_squared_error(y_train, ypred_train1, squared=False)\n",
    "    result_valid = mean_squared_error(y_valid, ypred_valid1, squared=False)\n",
    "\n",
    "    ypred_test1 = reg1.predict(X_test)\n",
    "    dict_result1[index] = ypred_test1\n",
    "\n",
    "    print(\"Take time: \", time.time() - t)\n",
    "    print(\"Train_score: {}  Valid_score: {}\".format(result_train, result_valid))\n",
    "    print(\"-------------\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ypred_test = np.mean([value for key, value in dict_result.items()], axis=0)\n",
    "pd.DataFrame(data = {\"{}\".format(target_): ypred_test, \"index\": test_index}).to_csv(\"submit_ridge.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ensemble"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
