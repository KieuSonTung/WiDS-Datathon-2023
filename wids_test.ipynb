{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder, LabelEncoder, RobustScaler, StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error\n",
    "from sklearn.linear_model import Ridge, Lasso, LassoCV, LinearRegression\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy.ma as ma\n",
    "from sklearn import base\n",
    "import warnings\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "path_train = \"data/train_data.csv\"\n",
    "path_test = \"data/test_data.csv\"\n",
    "target_ = \"contest-tmp2m-14d__tmp2m\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(path_train)\n",
    "df_test = pd.read_csv(path_test)\n",
    "\n",
    "date_col = \"startdate\"\n",
    "\n",
    "df_train[date_col] = pd.to_datetime(df_train[date_col])\n",
    "df_test[date_col] = pd.to_datetime(df_test[date_col])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'wind-hgt-250-2010-10'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/SonTung/WiDS/venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3803\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3802\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/SonTung/WiDS/venv/lib/python3.11/site-packages/pandas/_libs/index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/SonTung/WiDS/venv/lib/python3.11/site-packages/pandas/_libs/index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'wind-hgt-250-2010-10'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[53], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdf_train\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mwind-hgt-250-2010-10\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "File \u001B[0;32m~/SonTung/WiDS/venv/lib/python3.11/site-packages/pandas/core/frame.py:3805\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3804\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3805\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3806\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3807\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/SonTung/WiDS/venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3805\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3808\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3809\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3810\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'wind-hgt-250-2010-10'"
     ]
    }
   ],
   "source": [
    "df_train['wind-hgt-250-2010-10']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:03,  2.26it/s]\n"
     ]
    }
   ],
   "source": [
    "def filter_na_cols(df):\n",
    "    count_na_df = df.isna().sum()\n",
    "    if count_na_df[count_na_df > 0].tolist():\n",
    "        return count_na_df[count_na_df > 0]\n",
    "    else:\n",
    "        return 'Clean dataset'\n",
    "\n",
    "col_na = [\n",
    "    'nmme0-tmp2m-34w__ccsm30',\n",
    "    'nmme-tmp2m-56w__ccsm3',\n",
    "    'nmme-prate-34w__ccsm3',\n",
    "    'nmme0-prate-56w__ccsm30',\n",
    "    'nmme0-prate-34w__ccsm30',\n",
    "    'nmme-prate-56w__ccsm3',\n",
    "    'nmme-tmp2m-34w__ccsm3']\n",
    "\n",
    "g_means =  ['nmme0-tmp2m-34w__nmme0mean',\n",
    " 'nmme-tmp2m-56w__nmmemean',\n",
    " 'nmme-prate-34w__nmmemean',\n",
    " 'nmme0-prate-56w__nmme0mean',\n",
    " 'nmme0-prate-34w__nmme0mean',\n",
    " 'nmme-prate-56w__nmmemean',\n",
    " 'nmme-tmp2m-34w__nmmemean']\n",
    "\n",
    "\n",
    "g_1 = ['nmme0-tmp2m-34w__cancm30',\n",
    "'nmme0-tmp2m-34w__cancm40',\n",
    "'nmme0-tmp2m-34w__ccsm40',\n",
    "'nmme0-tmp2m-34w__cfsv20',\n",
    "'nmme0-tmp2m-34w__gfdlflora0',\n",
    "'nmme0-tmp2m-34w__gfdlflorb0',\n",
    "'nmme0-tmp2m-34w__gfdl0',\n",
    "'nmme0-tmp2m-34w__nasa0']\n",
    "\n",
    "g_2 = ['nmme-tmp2m-56w__cancm3',\n",
    "'nmme-tmp2m-56w__cancm4',\n",
    "'nmme-tmp2m-56w__ccsm4',\n",
    "'nmme-tmp2m-56w__cfsv2',\n",
    "'nmme-tmp2m-56w__gfdl',\n",
    "'nmme-tmp2m-56w__gfdlflora',\n",
    "'nmme-tmp2m-56w__gfdlflorb',\n",
    "'nmme-tmp2m-56w__nasa']\n",
    "\n",
    "g_3 = ['nmme-prate-34w__cancm3',\n",
    "'nmme-prate-34w__cancm4',\n",
    "'nmme-prate-34w__ccsm4',\n",
    "'nmme-prate-34w__cfsv2',\n",
    "'nmme-prate-34w__gfdl',\n",
    "'nmme-prate-34w__gfdlflora',\n",
    "'nmme-prate-34w__gfdlflorb',\n",
    "'nmme-prate-34w__nasa']\n",
    "\n",
    "g_4 = [ 'nmme0-prate-56w__cancm30',\n",
    "'nmme0-prate-56w__cancm40',\n",
    "'nmme0-prate-56w__ccsm40',\n",
    "'nmme0-prate-56w__cfsv20',\n",
    "'nmme0-prate-56w__gfdlflora0',\n",
    "'nmme0-prate-56w__gfdlflorb0',\n",
    "'nmme0-prate-56w__gfdl0',\n",
    "'nmme0-prate-56w__nasa0']\n",
    "\n",
    "g_5 = ['nmme0-prate-34w__cancm30',\n",
    "'nmme0-prate-34w__cancm40',\n",
    "'nmme0-prate-34w__ccsm40',\n",
    "'nmme0-prate-34w__cfsv20',\n",
    "'nmme0-prate-34w__gfdlflora0',\n",
    "'nmme0-prate-34w__gfdlflorb0',\n",
    "'nmme0-prate-34w__gfdl0',\n",
    "'nmme0-prate-34w__nasa0']\n",
    "\n",
    "g_6 = ['nmme-prate-56w__cancm3',\n",
    "'nmme-prate-56w__cancm4',\n",
    "'nmme-prate-56w__ccsm4',\n",
    "'nmme-prate-56w__cfsv2',\n",
    "'nmme-prate-56w__gfdl',\n",
    "'nmme-prate-56w__gfdlflora',\n",
    "'nmme-prate-56w__gfdlflorb',\n",
    "'nmme-prate-56w__nasa']\n",
    "\n",
    "g_7 = ['nmme-tmp2m-34w__cancm3',\n",
    "'nmme-tmp2m-34w__cancm4',\n",
    "'nmme-tmp2m-34w__ccsm4',\n",
    "'nmme-tmp2m-34w__cfsv2',\n",
    "'nmme-tmp2m-34w__gfdl',\n",
    "'nmme-tmp2m-34w__gfdlflora',\n",
    "'nmme-tmp2m-34w__gfdlflorb',\n",
    "'nmme-tmp2m-34w__nasa']\n",
    "\n",
    "gs = [g_1, g_2, g_3, g_4, g_5, g_6, g_7]\n",
    "\n",
    "zip_cols = zip(col_na, gs, g_means)\n",
    "for c, g, m in tqdm(zip_cols):\n",
    "    df_train[c] = (df_train[m]*9) - df_train[g].sum(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "df_train.drop(columns='ccsm30', inplace=True)\n",
    "df_test.drop(columns='ccsm30', inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "target_ = 'contest-tmp2m-14d__tmp2m'\n",
    "\n",
    "col = [each for each in df_train.columns if \"contest\" in each and each != target_]\n",
    "\n",
    "def get_idx(lat, lon):\n",
    "    return str(round(lat, 4)) + \"_\" + str(round(lon, 4))\n",
    "\n",
    "df_train['idx'] = np.vectorize(get_idx)(df_train['lat'], df_train['lon'])\n",
    "df_test['idx'] = np.vectorize(get_idx)(df_test['lat'], df_test['lon'])\n",
    "\n",
    "for each in col:\n",
    "    df_train[each + \"_lag_1\"] = df_train.groupby(\"idx\")[each].shift(1).bfill()\n",
    "    df_test[each + \"_lag_1\"] = df_test.groupby(\"idx\")[each].shift(1).bfill()\n",
    "\n",
    "    df_train[each + \"_shift_1\"] = df_train.groupby(\"idx\")[each].shift(-1).ffill()\n",
    "    df_test[each + \"_shift_1\"] = df_test.groupby(\"idx\")[each].shift(-1).ffill()\n",
    "\n",
    "    df_train[each + \"_lag_2\"] = df_train.groupby(\"idx\")[each].shift(2).bfill()\n",
    "    df_test[each + \"_lag_2\"] = df_test.groupby(\"idx\")[each].shift(2).bfill()\n",
    "\n",
    "    df_train[each + \"_shift_2\"] = df_train.groupby(\"idx\")[each].shift(-2).ffill()\n",
    "    df_test[each + \"_shift_2\"] = df_test.groupby(\"idx\")[each].shift(-2).ffill()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "imp_contest_cols = [\n",
    "    'contest-pevpr-sfc-gauss-14d__pevpr',\n",
    "    'contest-pres-sfc-gauss-14d__pres',\n",
    "    'contest-prwtr-eatm-14d__prwtr',\n",
    "    'contest-slp-14d__slp',\n",
    "    'contest-wind-h10-14d__wind-hgt-10',\n",
    "    'contest-wind-h100-14d__wind-hgt-100',\n",
    "    'contest-wind-h500-14d__wind-hgt-500',\n",
    "    'contest-wind-uwnd-250-14d__wind-uwnd-250',\n",
    "    'contest-wind-vwnd-925-14d__wind-vwnd-925'\n",
    "]\n",
    "\n",
    "def get_name_cols(suffix=''):\n",
    "    name_cols = [col + f'{suffix}' for col in imp_contest_cols]\n",
    "\n",
    "    return name_cols\n",
    "\n",
    "def feature_engineer(df, cols):\n",
    "\n",
    "    # df.loc[:, 'idx'] = np.vectorize(get_idx)(df['lat'], df['lon'])\n",
    "    df.loc[:, 'month'] = df['startdate'].dt.month\n",
    "    df.loc[:, 'year']  = df['startdate'].dt.year\n",
    "\n",
    "    mean_contest_cols = df.groupby(['idx', 'month', 'year'])[cols].transform(lambda x: x.mean()) \\\n",
    "        .rename(columns=dict(zip(cols, get_name_cols('_mean'))))\n",
    "    std_contest_cols = df.groupby(['idx', 'month', 'year'])[cols].transform(lambda x: x.std()) \\\n",
    "        .rename(columns=dict(zip(cols, get_name_cols('_std'))))\n",
    "    rolling_mean_contest_cols = df.groupby('idx')[cols].transform(lambda x: x.rolling(window=7, min_periods=3, win_type=\"triang\").mean()) \\\n",
    "        .rename(columns=dict(zip(cols, get_name_cols('_rolling_mean'))))\n",
    "    rolling_std_contest_cols = df.groupby('idx')[cols].transform(lambda x: x.rolling(window=7, min_periods=3).std()) \\\n",
    "        .rename(columns=dict(zip(cols, get_name_cols('_rolling_std'))))\n",
    "    expanding_mean_contest_cols = df.groupby('idx')[cols].transform(lambda x: x.expanding(2).mean()) \\\n",
    "        .rename(columns=dict(zip(cols, get_name_cols('_expanding_mean'))))\n",
    "    expanding_std_contest_cols = df.groupby('idx')[cols].transform(lambda x: x.expanding(2).std()) \\\n",
    "        .rename(columns=dict(zip(cols, get_name_cols('_expanding_std'))))\n",
    "    exponentially_weighted_average = df.groupby('idx')[cols].transform(lambda x: x.shift(1).ewm(alpha=0.95).mean()) \\\n",
    "        .rename(columns=dict(zip(cols, get_name_cols('_ewa'))))\n",
    "\n",
    "    df = pd.concat([df, mean_contest_cols, std_contest_cols, rolling_mean_contest_cols,\n",
    "                    rolling_std_contest_cols, expanding_mean_contest_cols,\n",
    "                    expanding_std_contest_cols, exponentially_weighted_average], axis=1)\n",
    "\n",
    "    df = df.fillna(method='bfill')\n",
    "    df.drop(columns=['month', 'year'], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train = feature_engineer(df_train, imp_contest_cols)\n",
    "df_test = feature_engineer(df_test, imp_contest_cols)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "df_train.drop(columns=[target_, 'index'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(50, 50))\n",
    "ax = plt.plot(df_train['startdate'], df_train['contest-precip-14d__precip'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
